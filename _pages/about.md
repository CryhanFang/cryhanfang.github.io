---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>
Welcome! My name is Han Fang, I work at TeleAI ÔºàChina TelecomÔºâas a research engineer now in Beijing.

I am now working on video-text retrieval, video understanding, text-to-image generation and multimodal large language models. If you are seeking any form of **academic cooperation**, please feel free to email me at [ fanghan1996@outlook.com](mailto:fanghan1996@outlook.com). We are hiring interns!

I obtained my Master's degree in Information and Communication Engineering from BUPT in 2022 and Bachelor's degree in Telecommunications Engineering with Management from BUPT in 2019.

My research interest includes face recognition, video/image-text understanding and text-to-image generation. I have published 10+ papers at the top international AI journals and conferences such as TMM, ECCV, AAAI, ACM MM, and ICME.

# üî• News
- *2024.12*: &nbsp;üéâüéâ Two papers are accepted by ICASSP 2025.
- *2024.12*: &nbsp;üéâüéâ One paper is accepted by AAAI 2025.
- *2024.07*: &nbsp;üéâüéâ One paper is accepted by ACM MM 2024.
- *2024.03*: &nbsp;üéâüéâ Two papers are accepted by ICME 2024 (oral presentation).
- *2023.07*: &nbsp;üéâüéâ Two papers are accepted by ACM MM 2023.
- *2022.12*: &nbsp;üéâüéâ Our paper about video-text retrieval (CLIP2Video) is accedpted by TMM 2022.

# üìù Publications 



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2025</div><img src='images/TUNED.png' alt="sym2" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[Trusted Unified Feature-Neighborhood Dynamics for Multi-View Classification](https://arxiv.org/pdf/2409.00755)
Haojian Huang, Chuanyu Qin, Zhe Liu, Kaijing Ma, Jin Chen, **Han Fang**, Chao Ban, Hao Sun, Zhongjiang He
[**Project**](https://github.com/CryhanFang/CLIP2Video) <strong><span class='show_paper_citations' data='kjeKM7gAAAAJ:UeHWp8X0CEIC'></span></strong>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TMM 2022</div><img src='images/clip2video.png' alt="sym1" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[Transferring Image-CLIP to Video-Text Retrieval via Temporal Relations](https://ieeexplore.ieee.org/abstract/document/9973385/)
**Han Fang**, Pengfei Xiong, Luhui Xu, Wenhan Luo
[**Project**](https://github.com/CryhanFang/CLIP2Video) <strong><span class='show_paper_citations' data='kjeKM7gAAAAJ:UeHWp8X0CEIC'></span></strong>
</div>
</div>




<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CCBR 2022</div><img src='images/project-mlfw.jpg' alt="sym3" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[MLFW: A Database for Face Recognition on Masked Faces](https://arxiv.org/pdf/2109.05804/)
Chengrui Wang, **Han Fang**, Yaoyao Zhong, Weihong Deng
[**Dataset**](http://whdeng.cn/mlfw) <strong><span class='show_paper_citations' data='kjeKM7gAAAAJ:UeHWp8X0CEIC'></span></strong>
</div>
</div>

- `ICASSP 2025` <span style="color:red"></span> [FASTER: Face Attribute Sliders with Semantic  Rewards](), Jingyan Chen, Lanxiang Zhou, **Han Fang**, et al.
- `ICASSP 2025` <span style="color:red"></span> [ViCo: A Multitask Video-enhanced and Cognition-preserving Modality Alignment Training Framework](), Zhenda Yu, Jin Chen, Jiayu Shen, Lanxiang Zhou, **Han Fang**, et al.
- `AAAI 2025` <span style="color:red"></span> [Trusted Unified Feature-Neighborhood Dynamics for Multi-View Classification](https://arxiv.org/pdf/2409.00755), Haojian Huang, Chuanyu Qin, Zhe Liu, Kaijing Ma, Jin Chen, **Han Fang**, et al.
- `ACM MM 2024` <span style="color:red"></span> [GOAL: Grounded text-to-image Synthesis with Joint Layout Alignment Tuning](https://openreview.net/forum?id=N6hFKeLOfu), Yaqi Li, **Han Fang**, et al.
- `ICME 2024` <span style="color:red">(Oral)</span> [ProTA: Probabilistic Token Aggregation for Text-Video Retrieval](https://arxiv.org/pdf/2404.12216), **Han Fang**, et al.
- `ICME 2024` <span style="color:red">(Oral)</span> [Disentangle and Denoise: Tackling Context Misalignment for Video Moment Retrieval](https://arxiv.org/pdf/2408.07600), Kaijing Ma, **Han Fang**, et al.
- `ICCVW 2023` [Alignment and Generation Adapter for Efficient Video-text Understanding]([[https://arxiv.org/pdf/2404.12216](https://arxiv.org/pdf/2305.07910](https://openaccess.thecvf.com/content/ICCV2023W/CLVL/papers/Fang_Alignment_and_Generation_Adapter_for_Efficient_Video-Text_Understanding_ICCVW_2023_paper.pdf))), **Han Fang**, et al.
- `ICCVW 2023` [LLaViLo: Boosting Video Moment Retrieval via Adapter-Based Multimodal Modeling]([https://dl.acm.org/doi/abs/10.1145/3581783.3611916](https://openaccess.thecvf.com/content/ICCV2023W/CLVL/papers/Ma_LLaViLo_Boosting_Video_Moment_Retrieval_via_Adapter-Based_Multimodal_Modeling_ICCVW_2023_paper.pdf)), Kaijing Ma, **Han Fang**, et al.
- `ACM MM 2023` [Mask to Reconstruct: Cooperative Semantics Completion for Video-text Retrieval]([https://arxiv.org/pdf/2404.12216](https://arxiv.org/pdf/2305.07910)), **Han Fang**, et al.
- `ACM MM 2023` [A Baseline Investigation: Transformer-based Cross-view Baseline for Text-based Person Search](https://dl.acm.org/doi/abs/10.1145/3581783.3611916), Xianghao Zang, Wei Gao, Ge Li, **Han Fang**, et al.
- `TMM 2022` [Transferring image-clip to video-text retrieval via temporal relations](https://arxiv.org/pdf/2106.11097), **Han Fang**, et al.
- `CCBR 2022` [Mlfw: A database for face recognition on masked faces](https://arxiv.org/pdf/2109.05804), ChengRui Wang, **Han Fang**, et al.
- `FG 2021` <span style="color:red">(Oral)</span> [Augmented Face Representation Learning via Transitive Distillation](https://ieeexplore.ieee.org/abstract/document/9666949), **Han Fang**, et al.
- `TMM 2021` [Dynamic training data dropout for robust deep face recognition](https://www.researchgate.net/profile/Yaoyao-Zhong-2/publication/355712968_Dynamic_Training_Data_Dropout_for_Robust_Deep_Face_Recognition/links/63253eeb071ea12e363c3f70/Dynamic-Training-Data-Dropout-for-Robust-Deep-Face-Recognition.pdf), Yaoyao Zhong, **Han Fang**, et al.
- `ICASSP 2021` [Adaptive Re-Balancing Network with Gate Mechanism for Long-Tailed Visual Question Answering](https://ieeexplore.ieee.org/abstract/document/9414074), Hongyu Chen, Ruifang Liu, **Han Fang**, et al.
- `ECCV 2020` [Generate to adapt: Resolution adaption network for surveillance face recognition](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123600732.pdf), **Han Fang**, et al.
- `CVPRW 2020` [Triple-GAN: Progressive face aging with triple translation loss](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w48/Fang_Triple-GAN_Progressive_Face_Aging_With_Triple_Translation_Loss_CVPRW_2020_paper.pdf),  **Han Fang**, et al.
- `IGTA 2018` [Semantic Segmentation of Aerial Image Using Fully Convolutional Network](), Junli Yang, Yiran Jiang, **Han Fang**, et al.

# üéñ Honors and Awards
- *2019, 2022* Beijing Excellent Graduate Award (Top 1%).
- *2019.05* Beijing Excellent Bachelor Dissertation Award (Top 3%).
- *2016, 2017, 2018, 2019, 2020, 2021* First-Class Scholarship of Beijing University of Posts and Telecommunications.



# üìñ Educations
- *2019.09 - 2022.06*, Master, Beijing University Of Posts And Telecommunications, Beijing.
- *2015.09 - 2019.06*, Undergraduate, Beijing University Of Posts And Telecommunications and Queen Mary University of London, Beijing.



# üíª Internships
- *2021.03 - 2021.09*, PCG, Tencent, Beijing.
- *2020.12 - 2021.02*, MIG, SenseTime, Beijing.
